{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2691,
     "status": "ok",
     "timestamp": 1560117897098,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "_L9PqHKcDybt",
    "outputId": "0d8688c2-e765-4014-8371-e4f46fc0e6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 1.13.1\n",
      "NP 1.16.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "import warnings\n",
    "print('TF',tf.__version__)\n",
    "print('NP',np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjGNQQCGUbDr"
   },
   "outputs": [],
   "source": [
    "##READING LABELS\n",
    "labels_path='../Label_train/'\n",
    "train_data = pd.read_csv(labels_path+'train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qy_rCzFvy9aS"
   },
   "outputs": [],
   "source": [
    "DELF_FOLDER='/mnt/disks/disk_b/Data/delf_features_np_min250_490k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 465186,
     "status": "ok",
     "timestamp": 1560118380935,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "7jOi8aybrjSA",
    "outputId": "e521706f-cb93-46ae-cf82-54d4dc608b5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import urllib\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.applications import ResNet50,InceptionResNetV2\n",
    "from keras.applications import DenseNet121\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Input\n",
    "from keras.layers import Activation, Add, BatchNormalization, Concatenate, Conv2D, Dense, Flatten, GlobalMaxPooling2D, \\\n",
    "    Lambda, MaxPooling2D, Reshape, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtefyzexmnfX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774042"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking present DELF feture files\n",
    "\n",
    "from os import listdir\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "defl_dir=DELF_FOLDER\n",
    "defl_list = [f[:-9] for f in listdir(defl_dir) if isfile(join(defl_dir, f))]\n",
    "len(defl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aC0Qt1icJT7"
   },
   "outputs": [],
   "source": [
    "# Double check all versus present DELF\n",
    "defl_list_df = pd.DataFrame(defl_list) \n",
    "Checked_df=train_data.set_index('id').join(defl_list_df.set_index(0),how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1187,
     "status": "ok",
     "timestamp": 1560124283941,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "QHXypU5ZiwAz",
    "outputId": "ecf7faee-ea18-47cb-c0d0-6bd13cc84dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of valid classes: 1067\n",
      "Total number of valid examples: 246836\n"
     ]
    }
   ],
   "source": [
    "NUM_THRESHOLD = 100\n",
    "train=Checked_df\n",
    "\n",
    "\n",
    "counts = dict(Counter(train['landmark_id']))\n",
    "landmarks_dict = {x:[] for x in train.landmark_id.unique() if counts[x] >= NUM_THRESHOLD}\n",
    "NUM_CLASSES = len(landmarks_dict)\n",
    "print(\"Total number of valid classes: {}\".format(NUM_CLASSES))\n",
    "\n",
    "i = 0\n",
    "landmark_to_idx = {}\n",
    "idx_to_landmark = []\n",
    "for k in landmarks_dict:\n",
    "    landmark_to_idx[k] = i\n",
    "    idx_to_landmark.append(k)\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "all_ids=train.index.tolist()\n",
    "\n",
    "all_landmarks = train['landmark_id'].tolist()\n",
    "\n",
    "\n",
    "valid_ids_dict = {x[0]:landmark_to_idx[x[1]] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict}\n",
    "valid_ids_list = [x[0] for x in zip(all_ids, all_landmarks) if x[1] in landmarks_dict]\n",
    "\n",
    "NUM_EXAMPLES = len(valid_ids_list)\n",
    "print(\"Total number of valid examples: {}\".format(NUM_EXAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1560124288701,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "60QPP1x6yO2g",
    "outputId": "60962650-5447-4877-837b-a65c8013f7e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train1_ids, test_ids = train_test_split(valid_ids_list, test_size=0.1)#1.2*NUM_CLASSES/NUM_EXAMPLES,random_state=1234)\n",
    "train_ids, validation_ids = train_test_split(train1_ids, test_size=0.2)#1.2*NUM_CLASSES/NUM_EXAMPLES,random_state=1234)\n",
    "print(len(train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHqq13Pqa6sl"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-119205aabb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdelf_num_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdelf_num_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelf_num_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;31m# If the file size is less than N, we need to make sure not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;31m# to seek past the beginning of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# checking average number of returned features\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "dir=DELF_FOLDER\n",
    "files = sorted(glob.glob(dir + '/*.npy'))\n",
    "delf_num_features = []\n",
    "for f in files:\n",
    "    delf_num_features.append(len(np.load(f)))\n",
    "\n",
    "print(len(delf_num_features))\n",
    "\n",
    "ll=[item for item in delf_num_features]\n",
    "import statistics\n",
    "print(min(ll), max(ll),statistics.median(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chL6Iovv73o2"
   },
   "outputs": [],
   "source": [
    "def download_delf(id_):\n",
    "  feature_path='/mnt/disks/disk_b/Data/delf_features_np_min250_490k/'\n",
    "  try:\n",
    "    #print(feature_path+id_+'.delf.npy')\n",
    "    f=np.load(feature_path+id_+'.delf.npy',allow_pickle=True)\n",
    "    #print(len(f))\n",
    "    if len(f)>=150:\n",
    "      return f[:150].reshape((150,40))\n",
    "    \n",
    "    else:\n",
    "      return np.array([])\n",
    "    \n",
    "    \n",
    "  except:\n",
    "    return np.array([])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3603,
     "status": "ok",
     "timestamp": 1560124301666,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "Cg9o_2FW1IkO",
    "outputId": "57147e07-fbf7-4ede-abc3-72f5b6cd20ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19346\n"
     ]
    }
   ],
   "source": [
    "valid_x=[]\n",
    "valid_y=[]\n",
    "\n",
    "for item in validation_ids:\n",
    "\n",
    "    valid_xi=download_delf(item)\n",
    "\n",
    "    valid_yi=valid_ids_dict[item]\n",
    "    if valid_xi.shape[0]>0:\n",
    "        valid_x.append(valid_xi)\n",
    "        valid_y.append(valid_yi)\n",
    "print(len(valid_x))\n",
    "\n",
    "y = np.zeros((len(valid_x), NUM_CLASSES))\n",
    "        \n",
    "for i in range(len(valid_y)):\n",
    "    y[i,valid_y[i]] = 1.\n",
    "valid_y=y\n",
    "valid_x=np.array(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2emkdnyUa1VC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class DataGenDEFL(Sequence):\n",
    "    def __init__(self, data, batch_size=24, verbose=1):\n",
    "        self.batch_size=batch_size\n",
    "        self.data_urls = data\n",
    "\n",
    "    def normalize(self,data):\n",
    "        return data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "      \n",
    "        number_of_crops=1\n",
    "        \n",
    "        \n",
    "        #print('Index: ',index)\n",
    "        batch_urls = random.sample(self.data_urls, int(self.batch_size/number_of_crops))\n",
    "        \n",
    "        batch_urls=self.data_urls[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        y_classes = []\n",
    "        f=np.array([])\n",
    "        F_list=[]\n",
    "        \n",
    "        #url is id\n",
    "        for url in batch_urls:\n",
    "            f=download_delf(url)\n",
    "            \n",
    "      \n",
    "            if f.shape[0]>0:\n",
    "              \n",
    "              F_list.append(f)\n",
    "              y_classes.append(valid_ids_dict[url.split(\"/\")[-1]])\n",
    "            \n",
    "     \n",
    "        \n",
    "        \n",
    "        F=np.array(F_list)\n",
    "        y = np.zeros((len(F_list), NUM_CLASSES))\n",
    "        \n",
    "        for i in range(len(y_classes)):\n",
    "            y[i,y_classes[i]] = 1.\n",
    "        \n",
    "  \n",
    "        \n",
    "        return F,y\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return int(len(train_ids)/self.batch_size)-1\n",
    "      \n",
    "def binary_crossentropy_n_cat(y_t, y_p):\n",
    "    return keras.metrics.binary_crossentropy(y_t, y_p) * NUM_CLASSES\n",
    "\n",
    "#GeM\n",
    "\n",
    "gm_exp = tf.Variable(3., dtype=tf.float32)\n",
    "  \n",
    "def accuracy_class(y_true, y_pred):\n",
    "    true = K.argmax(y_true, axis=1)\n",
    "    pred = K.argmax(y_pred, axis=1)\n",
    "    matches = K.equal(true, pred)\n",
    "    return K.mean(matches)\n",
    "  \n",
    "def batch_GAP(y_t, y_p):\n",
    "  \n",
    "    import tensorflow as tf\n",
    "    pred_cat = tf.argmax(y_p, axis=-1)    \n",
    "    y_t_cat = tf.argmax(y_t, axis=-1) * tf.cast(\n",
    "        tf.reduce_sum(y_t, axis=-1), tf.int64)\n",
    "    \n",
    "    n_pred = tf.shape(pred_cat)[0]\n",
    "    is_c = tf.cast(tf.equal(pred_cat, y_t_cat), tf.float32)\n",
    "\n",
    "    GAP = tf.reduce_mean(\n",
    "          tf.cumsum(is_c) * is_c / tf.cast(\n",
    "              tf.range(1, n_pred + 1), \n",
    "              dtype=tf.float32))\n",
    "    \n",
    "    return GAP  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1560124310908,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "jHd6pj486_jf",
    "outputId": "93d37a77-7ed6-4929-d01d-fa966bd24231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150, 40)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 150, 1067)         43747     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 150, 1067)         4268      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 150, 1067)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 150, 1067)         0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 150, 1067)         1139556   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 150, 1067)         4268      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 150, 1067)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150, 1067)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160050)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1067)              170774417 \n",
      "=================================================================\n",
      "Total params: 171,966,256\n",
      "Trainable params: 171,961,988\n",
      "Non-trainable params: 4,268\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#simple model\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import GlobalMaxPooling1D,GlobalAveragePooling1D\n",
    "\n",
    "input_shape = (150, 40)\n",
    "\n",
    "X_feat = Input(input_shape)\n",
    "#Add bottleneck layers (Dense + BN + Activation + Dropout + Output)\n",
    "                                \n",
    "X = Dense(NUM_CLASSES)(X_feat)\n",
    "X=BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "\n",
    "X = Dense(NUM_CLASSES)(X)\n",
    "X=BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "\n",
    "X=Flatten()(X)\n",
    "\n",
    "X = Dense(NUM_CLASSES, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=X_feat, outputs=X)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113864,
     "status": "ok",
     "timestamp": 1560124605364,
     "user": {
      "displayName": "Ekaterina Kastrama",
      "photoUrl": "",
      "userId": "16919877199024167270"
     },
     "user_tz": 420
    },
    "id": "dvF-Kx3dtznZ",
    "outputId": "af364a14-a4c2-40e9-a80e-1f430674b9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "693/693 [==============================] - 308s 445ms/step - loss: 0.0087 - accuracy_class: 0.1356 - batch_GAP: 0.0255 - binary_crossentropy_n_cat: 9.2725 - val_loss: 0.0099 - val_accuracy_class: 0.1996 - val_batch_GAP: 0.0475 - val_binary_crossentropy_n_cat: 10.5693\n",
      "Epoch 2/20\n",
      "693/693 [==============================] - 285s 412ms/step - loss: 0.0049 - accuracy_class: 0.5243 - batch_GAP: 0.2931 - binary_crossentropy_n_cat: 5.1867 - val_loss: 0.0070 - val_accuracy_class: 0.2496 - val_batch_GAP: 0.0688 - val_binary_crossentropy_n_cat: 7.4722\n",
      "Epoch 3/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 0.0024 - accuracy_class: 0.7671 - batch_GAP: 0.6021 - binary_crossentropy_n_cat: 2.5237 - val_loss: 0.0062 - val_accuracy_class: 0.2708 - val_batch_GAP: 0.0821 - val_binary_crossentropy_n_cat: 6.6646\n",
      "Epoch 4/20\n",
      "693/693 [==============================] - 285s 412ms/step - loss: 0.0013 - accuracy_class: 0.8808 - batch_GAP: 0.7820 - binary_crossentropy_n_cat: 1.3643 - val_loss: 0.0062 - val_accuracy_class: 0.2657 - val_batch_GAP: 0.0767 - val_binary_crossentropy_n_cat: 6.6380\n",
      "Epoch 5/20\n",
      "693/693 [==============================] - 287s 414ms/step - loss: 9.1013e-04 - accuracy_class: 0.9179 - batch_GAP: 0.8468 - binary_crossentropy_n_cat: 0.9711 - val_loss: 0.0062 - val_accuracy_class: 0.2806 - val_batch_GAP: 0.0879 - val_binary_crossentropy_n_cat: 6.5921\n",
      "Epoch 6/20\n",
      "693/693 [==============================] - 287s 414ms/step - loss: 8.0280e-04 - accuracy_class: 0.9260 - batch_GAP: 0.8603 - binary_crossentropy_n_cat: 0.8566 - val_loss: 0.0066 - val_accuracy_class: 0.2732 - val_batch_GAP: 0.0852 - val_binary_crossentropy_n_cat: 7.0770\n",
      "Epoch 7/20\n",
      "693/693 [==============================] - 287s 414ms/step - loss: 9.0195e-04 - accuracy_class: 0.9156 - batch_GAP: 0.8429 - binary_crossentropy_n_cat: 0.9624 - val_loss: 0.0072 - val_accuracy_class: 0.2577 - val_batch_GAP: 0.0758 - val_binary_crossentropy_n_cat: 7.7257\n",
      "Epoch 8/20\n",
      "693/693 [==============================] - 288s 416ms/step - loss: 9.1815e-04 - accuracy_class: 0.9168 - batch_GAP: 0.8447 - binary_crossentropy_n_cat: 0.9797 - val_loss: 0.0075 - val_accuracy_class: 0.2608 - val_batch_GAP: 0.0780 - val_binary_crossentropy_n_cat: 7.9700\n",
      "Epoch 9/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 5.6128e-04 - accuracy_class: 0.9660 - batch_GAP: 0.9352 - binary_crossentropy_n_cat: 0.5989 - val_loss: 0.0062 - val_accuracy_class: 0.3061 - val_batch_GAP: 0.1035 - val_binary_crossentropy_n_cat: 6.6080\n",
      "Epoch 10/20\n",
      "693/693 [==============================] - 286s 412ms/step - loss: 4.7738e-04 - accuracy_class: 0.9724 - batch_GAP: 0.9473 - binary_crossentropy_n_cat: 0.5094 - val_loss: 0.0062 - val_accuracy_class: 0.3041 - val_batch_GAP: 0.1004 - val_binary_crossentropy_n_cat: 6.6082\n",
      "Epoch 11/20\n",
      "693/693 [==============================] - 286s 412ms/step - loss: 4.5240e-04 - accuracy_class: 0.9737 - batch_GAP: 0.9494 - binary_crossentropy_n_cat: 0.4827 - val_loss: 0.0062 - val_accuracy_class: 0.3038 - val_batch_GAP: 0.1005 - val_binary_crossentropy_n_cat: 6.6371\n",
      "Epoch 12/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 4.1588e-04 - accuracy_class: 0.9761 - batch_GAP: 0.9543 - binary_crossentropy_n_cat: 0.4437 - val_loss: 0.0062 - val_accuracy_class: 0.3030 - val_batch_GAP: 0.1008 - val_binary_crossentropy_n_cat: 6.6640\n",
      "Epoch 13/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 4.1209e-04 - accuracy_class: 0.9765 - batch_GAP: 0.9549 - binary_crossentropy_n_cat: 0.4397 - val_loss: 0.0062 - val_accuracy_class: 0.3034 - val_batch_GAP: 0.1036 - val_binary_crossentropy_n_cat: 6.6148\n",
      "Epoch 14/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 4.0701e-04 - accuracy_class: 0.9771 - batch_GAP: 0.9559 - binary_crossentropy_n_cat: 0.4343 - val_loss: 0.0060 - val_accuracy_class: 0.3154 - val_batch_GAP: 0.1087 - val_binary_crossentropy_n_cat: 6.4306\n",
      "Epoch 15/20\n",
      "693/693 [==============================] - 288s 415ms/step - loss: 3.9384e-04 - accuracy_class: 0.9773 - batch_GAP: 0.9562 - binary_crossentropy_n_cat: 0.4202 - val_loss: 0.0060 - val_accuracy_class: 0.3142 - val_batch_GAP: 0.1117 - val_binary_crossentropy_n_cat: 6.4052\n",
      "Epoch 16/20\n",
      "693/693 [==============================] - 286s 413ms/step - loss: 3.8800e-04 - accuracy_class: 0.9774 - batch_GAP: 0.9564 - binary_crossentropy_n_cat: 0.4140 - val_loss: 0.0060 - val_accuracy_class: 0.3163 - val_batch_GAP: 0.1103 - val_binary_crossentropy_n_cat: 6.3551\n",
      "Epoch 17/20\n",
      " 82/693 [==>...........................] - ETA: 4:02 - loss: 3.4445e-04 - accuracy_class: 0.9798 - batch_GAP: 0.9609 - binary_crossentropy_n_cat: 0.3675"
     ]
    }
   ],
   "source": [
    "#os.chdir(\"/content/drive/My Drive/CS231n/Project/Data/Train/0/0/0/\")\n",
    "from keras.callbacks import History, CSVLogger,ReduceLROnPlateau,ModelCheckpoint\n",
    "history = keras.callbacks.History()\n",
    "\n",
    "model_name='delf_0610'\n",
    "\n",
    "LOG_DIR='/home/kate_for_it/Project/LOG/'\n",
    "Check_DIR='/home/kate_for_it/Project/Checkpoint/'\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(LOG_DIR+'training_'+model_name+'.log')\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(0.0001)\n",
    "#opt = Adam(0.00001)\n",
    "\n",
    "checkpoint_name=model_name+'.h5'\n",
    "checkpoint_filepath=Check_DIR+checkpoint_name\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=5, min_lr=0.000001)\n",
    "\n",
    "checkpoint=keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[accuracy_class,batch_GAP,binary_crossentropy_n_cat])\n",
    "\n",
    "#check dir\n",
    "if os. path. isfile(checkpoint_filepath):\n",
    "\n",
    "  model.load_weights(checkpoint_filepath)\n",
    "\n",
    "  print(\"Best weights loaded\")\n",
    "  \n",
    "model.fit_generator(generator=DataGenDEFL(train_ids, batch_size=256),\n",
    "                    shuffle=True,\n",
    "                    validation_data=[valid_x, valid_y],\n",
    "                    epochs=20,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=8,\n",
    "                    verbose=1,\n",
    "                    callbacks=[history,csv_logger,checkpoint#,reduce_lr,\n",
    "                              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Udpn6JEFAyfw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_=valid_x\n",
    "y_=valid_y\n",
    "\n",
    "def val_gap(x_,y_):\n",
    "\n",
    "  result=model.predict(x_, batch_size=128, verbose=0, steps=None)\n",
    "\n",
    "  true_=y_.astype('int64')\n",
    "  pred_=result\n",
    "\n",
    "  _,acc=tf.metrics.average_precision_at_k(true_,pred_,1)\n",
    "  custom_gap=batch_GAP(true_,pred_)\n",
    "\n",
    "  sess = tf.Session()\n",
    "  sess.run(tf.local_variables_initializer())\n",
    "\n",
    "  print('Validation GAP: ',sess.run(acc))\n",
    "  print('Custom GAP: ', sess.run(custom_gap))\n",
    "\n",
    "val_gap(x_,y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fh9TEBbo1rQZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#history\n",
    "#loss: 0.0086 - accuracy_class\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['batch_GAP'])\n",
    "plt.plot(history.history['val_batch_GAP'])\n",
    "plt.title('Batch GAP')\n",
    "plt.ylabel('GAP')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy_class'])\n",
    "plt.plot(history.history['val_accuracy_class'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5. DELF_Features.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
